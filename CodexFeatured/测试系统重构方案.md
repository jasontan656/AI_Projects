# 测试系统重构方案

**重构日期**：2025-10-11
**核心理念**：保留原有Test系列的完整组件设计，改造成类似开发工作流的5步结构

---

## 一、用户需求理解

### 核心要求

1. **不是简单脚本**：测试需要完整的组件，不是随便写个脚本就能搞定
2. **足够的随机性**：测试场景要多样（大文件、小文件、并发、边界等）
3. **保留原有流程**：Test系列的组件化思想必须保留
4. **改造成5步结构**：类似开发工作流的逐层细化
5. **从源头考虑问题**：Debugging时从项目整体考虑，不是死磕单个bug

### 原有系统保留的核心

- ✅ 完整的pytest测试组件结构
- ✅ SimulationTest目录规范
- ✅ 测试专用宪法（SimulationTestingConstitution）
- ✅ requirements.txt（pytest生态）
- ✅ run_local_simulation_tests.py（测试执行器）
- ✅ 结构化日志（debug.log, error.log）
- ✅ HTML/JSON测试报告

---

## 二、新的5步工作流设计

```
Step 1: TestScenarioAnalysis_V2（测试场景分析）
  ↓ 生成测试场景文档（从7个维度分析，50-100个场景）
  ↓ 人工审核
  ↓
Step 2: TestScenarioSpecify_V2（测试场景精化，可选）
  ↓ 精化测试场景文档
  ↓ 人工审核
  ↓
Step 3: TestPlanGeneration_V2（测试计划生成）
  ↓ 生成测试计划文档（如何组织测试代码）
  ↓ 人工审核
  ↓
Step 4: TestTechDecisions_V2（测试技术选型）
  ↓ 生成技术决策文档（用什么工具、如何随机化）
  ↓ 人工审核
  ↓
Step 5: TestExecuteAndDebug_V2（测试执行与调试）
  ↓ 实现测试代码、运行、Debugging
  ↓
测试完成
```

---

## 三、Step 1: TestScenarioAnalysis_V2（已完成）

### 核心功能

**深度理解项目**：
1. 读取所有开发文档（需求、计划、技术决策、任务清单）
2. 加载测试专用宪法（SimulationTestingConstitution.yaml）
3. 扫描项目代码（index.yaml + 实际代码）
4. 理解实现细节（API端点、CLI命令、Celery任务、依赖服务）

**发散性思考测试场景**（7个维度）：
1. **功能覆盖**：每个功能至少1个场景（正常、异常、边界）
2. **数据多样性**：小/中/大数据量、特殊字符、边界情况
3. **并发与性能**：单用户、10并发、100并发、持续压力
4. **配置分支**：Redis开/关、MongoDB本地/远程、各种配置组合
5. **异常与错误恢复**：网络超时、服务重启、资源不足
6. **依赖服务状态**：Redis/MongoDB/RabbitMQ/Chromadb 正常/宕机
7. **真实使用场景**：基于需求文档的典型用户流程

**随机化设计**（关键！）：
- 每个场景都有随机化策略
- 数据量随机（如10-20条随机）
- 顺序随机
- 延迟随机
- 失败注入（10%概率模拟API失败）

**输出示例**：

```markdown
# 测试场景文档：TelegramCuration

## 2.1 维度1：功能覆盖

### Scenario-1.1：正常导入小文件
- 优先级：P0
- 描述：导入包含10-20条消息的HTML文件
- 输入：test_data/telegram_small.html（18条消息）
- 操作：
  1. 调用API: POST /api/telegram-curation/ingest/start
  2. 轮询任务状态
  3. 等待完成
- 预期输出：
  * 任务状态：completed
  * 解析消息数：18条
  * MongoDB包含18条记录
- 验收标准：
  * 响应时间 < 30秒
  * 所有字段完整
  * 无解析错误
- 随机化策略：
  * 消息内容随机生成
  * 消息顺序随机打乱
- 依赖关系：无

### Scenario-1.2：大文件导入
- 优先级：P1
- 描述：导入10000条消息
- 随机化策略：
  * 消息数量：9000-11000随机
  * 消息长度：10-500字符随机
...

## 场景统计

| 维度 | 场景数 | P0 | P1 | P2 | P3 |
|------|-------|----|----|----|----|
| 功能覆盖 | 15 | 5 | 7 | 2 | 1 |
| 数据多样性 | 10 | 2 | 6 | 2 | 0 |
| 并发性能 | 8 | 1 | 5 | 2 | 0 |
| 配置分支 | 12 | 4 | 6 | 2 | 0 |
| 异常恢复 | 10 | 2 | 6 | 2 | 0 |
| 依赖服务 | 8 | 2 | 4 | 2 | 0 |
| 真实场景 | 5 | 3 | 2 | 0 | 0 |
| **总计** | **68** | **19** | **36** | **12** | **1** |
```

### 与原有TestAnalyzeSituation的区别

| 维度 | 原TestAnalyzeSituation | 新TestScenarioAnalysis_V2 |
|------|----------------------|--------------------------|
| 理解深度 | 基础 | 深度（扫描代码、理解实现） |
| 场景维度 | 单一 | 7个维度 |
| 场景数量 | ~10个 | 50-100个 |
| 随机化 | 无明确策略 | 每个场景都有随机化策略 |
| 优先级 | 无 | P0/P1/P2/P3 |
| 依赖关系 | 无 | 明确依赖关系 |
| 验收标准 | 模糊 | 具体可量化 |

---

## 四、Step 2: TestScenarioSpecify_V2（待创建）

### 设计思路

**类似DevFuncDemandsSpecify_V2**，但针对测试场景：
- 用户阅读测试场景文档后，发现需要调整
- 增加新的测试场景
- 修改某个场景的验收标准
- 调整场景优先级
- 调整随机化策略

**输入**：
- 现有测试场景文档
- 用户补充需求（通过-a参数）

**输出**：
- 更新后的测试场景文档
- 修改标记 `<!-- MODIFIED: ... -->`
- 修改历史记录

**示例**：
```bash
codex -p .codex/prompts/TestScenarioSpecify_V2.md -a "增加场景：测试100并发用户"
```

---

## 五、Step 3: TestPlanGeneration_V2（待创建）

### 设计思路

**基于测试场景文档，生成测试计划**：
- 如何组织测试代码？
- 目录结构如何设计？
- 测试数据如何准备？
- 测试环境如何搭建？
- 测试执行顺序？

**输入**：
- 测试场景文档（Step 1输出）

**输出**：
- 测试计划文档（TestPlan.md）

**内容示例**：

```markdown
# 测试计划：TelegramCuration

## 1. 目录结构

SimulationTest/TelegramCuration_testplan/
├── test_cases/          # 测试用例
│   ├── test_功能覆盖.py
│   ├── test_数据多样性.py
│   ├── test_并发性能.py
│   ├── test_配置分支.py
│   ├── test_异常恢复.py
│   ├── test_依赖服务.py
│   └── test_真实场景.py
├── test_data/           # 测试数据
│   ├── generators/      # 数据生成器
│   │   ├── generate_telegram_html.py
│   │   └── generate_random_messages.py
│   └── fixtures/        # 固定测试数据
│       └── sample.html
├── results/             # 测试结果
│   ├── report.json
│   └── report.html
├── logs/                # 日志
│   ├── debug.log
│   └── error.log
├── utils/               # 工具函数
│   ├── api_client.py    # API调用封装
│   ├── db_client.py     # 数据库客户端
│   └── random_utils.py  # 随机化工具
├── requirements.txt     # 依赖
└── run_tests.py         # 测试执行器

## 2. 测试数据准备

### 2.1 数据生成器设计

- generate_telegram_html.py:
  * 生成指定数量的消息
  * 支持随机化（内容、顺序）
  * 支持特殊字符注入

### 2.2 数据管理

- 小文件：预生成并缓存
- 大文件：动态生成
- 特殊文件：手工准备

## 3. 测试环境

### 3.1 依赖服务

- Redis: localhost:6379
- MongoDB: localhost:27017
- RabbitMQ: localhost:5672
- Chromadb: localhost:8001

### 3.2 环境检查

- 启动前检查所有服务状态
- 自动启动缺失服务（使用Docker）
- 环境隔离（使用独立数据库）

## 4. 测试执行顺序

1. 环境检查（检查依赖服务）
2. 数据准备（生成测试数据）
3. P0场景（19个，约2小时）
4. P1场景（36个，约4小时）
5. P2场景（12个，约2小时，可选）
6. 清理环境
```

---

## 六、Step 4: TestTechDecisions_V2（待创建）

### 设计思路

**技术选型决策**：
- 用什么测试框架？（pytest）
- 用什么随机化库？（faker、random）
- 用什么并发工具？（threading、multiprocessing）
- 用什么模拟工具？（responses、mock）
- 如何生成报告？（pytest-html、pytest-json-report）

**随机化技术细节**：
- 如何实现数据随机化？
- 如何实现失败注入？
- 如何控制随机种子（可复现）？

**输入**：
- 测试场景文档
- 测试计划文档

**输出**：
- 技术决策文档（TestTechDecisions.md）

**内容示例**：

```markdown
# 测试技术决策：TelegramCuration

## 1. 依赖清单

| 依赖 | 版本 | 用途 |
|------|------|------|
| pytest | 7.4.3 | 测试框架 |
| pytest-asyncio | 0.21.1 | 异步测试支持 |
| pytest-timeout | 2.2.0 | 超时控制 |
| pytest-json-report | 1.5.0 | JSON报告 |
| pytest-html | 4.1.1 | HTML报告 |
| requests | 2.31.0 | HTTP客户端 |
| faker | 20.1.0 | 随机数据生成 |
| redis | 5.0.1 | Redis客户端 |
| pymongo | 4.6.1 | MongoDB客户端 |
| psutil | 5.9.6 | 资源监控 |

## 2. 随机化实现

### 2.1 数据随机化

```python
from faker import Faker
import random

fake = Faker('zh_CN')

def generate_random_message():
    return {
        "sender": fake.name(),
        "text": fake.text(max_nb_chars=random.randint(10, 500)),
        "created_at": fake.date_time_between(start_date="-30d", end_date="now")
    }

def generate_telegram_html(count=None):
    if count is None:
        count = random.randint(10, 20)  # 随机数量
    
    messages = [generate_random_message() for _ in range(count)]
    random.shuffle(messages)  # 随机顺序
    
    return render_html(messages)
```

### 2.2 失败注入

```python
import random

def call_api_with_failure_injection(url, data):
    # 10%概率模拟超时
    if random.random() < 0.1:
        raise requests.Timeout("Simulated timeout")
    
    # 5%概率模拟500错误
    if random.random() < 0.05:
        raise requests.HTTPError("500 Server Error")
    
    # 正常调用
    return requests.post(url, json=data)
```

### 2.3 随机种子控制

```python
import random
import os

# 从环境变量读取种子（可复现）
seed = int(os.getenv("RANDOM_SEED", random.randint(1, 1000000)))
random.seed(seed)
fake = Faker()
fake.seed_instance(seed)

print(f"Random seed: {seed}")  # 记录种子，便于复现
```

## 3. 并发测试实现

```python
import threading
import queue

def concurrent_test(num_workers=10):
    results = queue.Queue()
    
    def worker():
        try:
            result = call_api()
            results.put(("success", result))
        except Exception as e:
            results.put(("error", str(e)))
    
    threads = [threading.Thread(target=worker) for _ in range(num_workers)]
    for t in threads:
        t.start()
    for t in threads:
        t.join()
    
    # 收集结果
    success_count = 0
    error_count = 0
    while not results.empty():
        status, _ = results.get()
        if status == "success":
            success_count += 1
        else:
            error_count += 1
    
    return success_count, error_count
```

## 4. 测试报告配置

pytest.ini:
```ini
[pytest]
addopts = 
    --json-report
    --json-report-file=results/report.json
    --html=results/report.html
    --self-contained-html
    --timeout=300
    --verbose
    --capture=no
log_cli = true
log_cli_level = INFO
```
```

---

## 七、Step 5: TestExecuteAndDebug_V2（待创建）

### 设计思路

**两个阶段**：

### 阶段1：测试实现
- 基于测试计划和技术决策，实现完整的测试组件
- 创建目录结构
- 编写测试用例（pytest）
- 编写数据生成器
- 编写测试执行器
- 配置日志和报告

### 阶段2：执行与Debugging
- 运行测试
- 收集结果
- 如果失败，进入Debugging模式

**Debugging模式**（关键！）：
- **不是死磕单个bug**
- **从项目整体考虑问题**
- 类似TestDebugging.md的思路：
  1. 理解项目背景（读需求文档、开发文档）
  2. 理解代码结构（读index.yaml、代码）
  3. 分析根因（配置缺失/功能未覆盖/逻辑错误/基础设施/环境差异）
  4. 提供根本性解决方案（不是临时修补）

**示例Debugging场景**：

```
问题：Celery任务一直pending，无法执行

传统思路（死磕）：
- 检查Celery配置
- 检查RabbitMQ连接
- 检查任务代码
- ...反复尝试各种修改

正确思路（从源头考虑）：
1. 理解项目背景：
   - 需求文档说：使用Celery处理异步任务
   - Tech_Decisions说：使用RabbitMQ作为broker
   - BackendConstitution说：所有异步任务必须通过Celery

2. 分析根因：
   - 检查Celery worker是否启动？（ps aux | grep celery）
   - 检查：没有Celery worker进程！
   
3. 根本原因：
   - 服务只启动了FastAPI（uvicorn）
   - 但没有启动Celery worker
   - 这是基础设施问题，不是代码bug

4. 根本性解决方案：
   - 在启动脚本中增加：
     ```bash
     # 启动FastAPI
     uvicorn main:app --host 0.0.0.0 --port 8000 &
     
     # 启动Celery worker
     celery -A main.celery_app worker --loglevel=info &
     ```
   - 更新文档：在部署文档中明确说明需要启动两个服务
   - 预防措施：在测试前检查Celery worker状态

5. 为何会发生：
   - 开发文档没有明确说明部署步骤
   - 测试计划没有检查基础设施
```

---

## 八、与开发工作流的对照

| 步骤 | 开发工作流 | 测试工作流 |
|------|-----------|-----------|
| 1 | DevFuncDemandsWrite | TestScenarioAnalysis |
| 1.5（可选） | DevFuncDemandsSpecify | TestScenarioSpecify |
| 2 | DevPlanGeneration | TestPlanGeneration |
| 3 | TechDecisionsGeneration | TestTechDecisions |
| 4 | DevPipelineGeneration | （合并到Step 5） |
| 5 | DevPiplineExcute | TestExecuteAndDebug |

**测试工作流的特点**：
- 没有单独的"Pipeline Generation"（任务清单），因为测试本身就是按场景执行
- Step 5同时包含"实现"和"执行"，因为测试代码和执行是紧密结合的

---

## 九、输出目录结构

```
Kobe/SimulationTest/
├── TelegramCuration_testscenarios.md      # Step 1输出
├── TelegramCuration_testplan.md           # Step 3输出
├── TelegramCuration_testtech.md           # Step 4输出
└── TelegramCuration_testplan/             # Step 5输出（测试组件）
    ├── test_cases/
    │   ├── test_功能覆盖.py
    │   ├── test_数据多样性.py
    │   ├── test_并发性能.py
    │   ├── test_配置分支.py
    │   ├── test_异常恢复.py
    │   ├── test_依赖服务.py
    │   └── test_真实场景.py
    ├── test_data/
    │   ├── generators/
    │   └── fixtures/
    ├── results/
    ├── logs/
    ├── utils/
    ├── requirements.txt
    └── run_tests.py
```

---

## 十、总结

### 重构核心

1. **保留原有组件化设计**：pytest、目录结构、日志、报告
2. **改造成5步工作流**：类似开发流程的逐层细化
3. **强化理解深度**：Step 1深度理解代码和实现
4. **强化随机性**：每个场景都有明确的随机化策略
5. **强化Debugging**：从项目整体考虑问题，不是死磕bug

### 关键改进

| 方面 | 原Test系列 | 新测试工作流 |
|------|-----------|-------------|
| 理解深度 | 浅（主要读需求） | 深（扫描代码、理解实现） |
| 场景设计 | 单维度 | 7个维度 |
| 随机性 | 无系统设计 | 每个场景都有策略 |
| 工作流结构 | 3步 | 5步（+可选精化） |
| Debugging | 局部修复 | 从源头考虑 |
| 文档产出 | 1个 | 3个（场景、计划、技术） |

---

## 十一、下一步工作

### 已完成
- [x] Step 1: TestScenarioAnalysis_V2
- [x] 配套脚本: get-test-context.ps1
- [x] 总体设计文档

### 待完成
- [ ] Step 2: TestScenarioSpecify_V2（测试场景精化）
- [ ] Step 3: TestPlanGeneration_V2（测试计划生成）
- [ ] Step 4: TestTechDecisions_V2（测试技术选型）
- [ ] Step 5: TestExecuteAndDebug_V2（测试执行与调试）
- [ ] 使用指南文档
- [ ] 快速参考文档

---

**重构版本**：2.0
**重构日期**：2025-10-11
**核心理念**：完整组件 + 5步工作流 + 深度理解 + 系统随机化 + 源头Debugging

