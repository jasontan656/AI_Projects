我现在构建的项目运行时任务特征和主要风险为，长耗时 + 多步 I/O：读库/抓取/清洗/入库，任一步崩溃都可能重头来。
并发切片：10～20 个 worker 同时跑，最怕重复处理或分片重叠。
进度可恢复：突发断电/机器挂了，已完成与未完成要可区分，且能从中间继续。
把“状态”分成三层，各司其职，组合起来才稳定：
# 瞬时执行态（Ephemeral Runtime State）：
- 放在内存里或 Redis，解决“运行期速度”和“短暂共享”。
- 崩溃后不保证完整；只是加速器，不做“权威记录”。
- 用 数据库（MongoDB）或对象存储保存检查点：已处理到哪个主键、URL、页码、时间窗口等。
# 消息持久态（Durable Message State）：

- 由 RabbitMQ 负责，把“任务已投递”这件事写盘（持久化队列 + 持久化消息 + 正确 ack）。

- 机器挂了能把未确认的消息重新投递给其他 worker。

# 业务权威态（Authoritative Progress State）：

- 断点续跑的依据；崩溃/重启靠它恢复。
# Celery 组件怎么搭：推荐职责拆分
- 消息中介（Broker）：用 RabbitMQ（消息持久化、确认/重投、路由、优先级）。

- 结果后端（Result Backend）：可用 Redis（查询快）,临时状态存储

- 权威进度/数据落地：MongoDB 做检查点、去重索引、原始/清洗数据落库。

# 用 MongoDB 做“切片 + 检查点 + 幂等”的三个常用套路

- 范围分片：按主键或时间窗口切片（例：id 或 created_at），每片一个任务；检查点记录“该片已处理到哪里”。

- 哈希取模：对稳定键 hash(key) % N，不同 worker 各吃一个模值，自然防重叠；检查点存“该模的游标”。

- 租约 + 心跳（爬虫 frontier）：领取 URL 时用 findOneAndUpdate 设置 lease_until、taken_by，定期续租；超时自动回收。

## 集合拆分（最小清单）
- 检查点/待处理队列/任务前沿/原始落地 + 幂等/运行记录/错误日志 命名规范： TaskCheckPoint，PendingTasks etc.. 

上述内容描述的文件置于唯一工作目录 `Kobe/TaskQueue`