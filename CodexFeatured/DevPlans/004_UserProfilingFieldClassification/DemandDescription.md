# 开发需求文档：用户画像字段识别与文档化

标识信息：INTENT_TITLE_2_4=UserProfilingFieldClassification；COUNT_3D=004；生成时间=2025-10-10 22:02:56
输出路径（模板）：D:/AI_Projects/CodexFeatured/DevPlans/004_UserProfilingFieldClassification/DemandDescription.md

## 1. 项目背景与目标
- 背景：现有转储文件 D:/AI_Projects/Visa/visa_db.sql 包含大量可用于构建用户画像的字段（如地址、电话、邮箱、身高、体重、证件号等）。目前缺乏从业务视角对相关字段进行系统化盘点、分级与文档化的产物，难以支撑后续审计、合规与复用。
- 目标：提供一套一次性运行的“字段分类与文档化”能力，输出面向业务使用者的数据库字段分类目录与判定说明，聚焦三个结论类别：与用户画像相关（True）、需审核（不确定/边界）、无关（False）。
- 受众：数据治理/合规/业务运营人员。
- 非技术目标：仅产生文档与审计材料，不对原数据库或业务系统产生任何改动。

## 2. 业务场景分析
- 典型场景
  - 合规审计：快速生成“与用户画像相关字段目录”及边界列表，支撑复核与留痕。
  - 数据资产治理：为字段分级、流向管控与使用授权提供基础清单。
  - 业务梳理：帮助业务人员理解各类字段与画像、服务、群组运营的关系。
- 输入与输出
  - 输入：本地 SQL 转储文件（路径固定为 D:/AI_Projects/Visa/visa_db.sql），无需连接真实数据库。
  - 输出：一份可审计、可复用的 Markdown 文档，附带字段清单、分类结果与文字理由；可选生成中间 JSON（字段采样与判定原始数据）。
- 运行方式与频率
  - 运行方式：按需手动触发，完成一次性扫描与判定。
  - 频率：在数据结构发生较大变更时再次运行；不要求长期常驻。
- 边界设定
  - 不进行数据库写入或结构改造。
  - 仅在本地指定目录下读取/写入文件，不对外部系统产生依赖。

## 3. 功能需求描述
- 字段枚举与建模对象识别
  - 从转储文件中识别所有表及字段，形成“库-表-字段”的业务清单。
  - 对每个字段识别其业务含义所需的上下文信息（表名、字段名、同表相关字段）。
- 字段代表性值采样
  - 为每个字段选取不超过 20 个代表性值，用于辅助业务判定；优先覆盖多样化取值与边界取值。
  - 采样结果写入中间数据文件，供后续判定与审计溯源。
- 业务判定与分级
  - 针对“字段+代表性值”，给出三类结论之一：True/需审核/False。
  - 为每个字段生成 30-50 字的中文判定理由，避免技术术语，强调业务可读性。
- 文档化与可审计性
  - 输出统一结构的 Markdown 文档：包含概览统计、按表的字段明细、分类结果、判定理由、需审核清单、名词与口径说明。
  - 文档需可由非技术人员直接阅读与复核，支持二次审阅与签章归档。
- 运行控制
  - 提供输入路径校验、输出目标目录校验与覆盖策略提示。
  - 支持在异常中断后基于中间数据断点续作（再次运行可复用已存在的采样/判定结果）。

## 4. 数据需求描述
- 数据来源
  - 本地 SQL 转储文件：D:/AI_Projects/Visa/visa_db.sql（以只读方式使用）。
- 数据类型与结构
  - 数据以 SQL 文本为载体，包含库、表、字段定义及插入语句；解析后形成“库-表-字段-样本值”的业务结构化视图。
- 数据量级（用于容量与时效预估）
  - 文件体量参考：≤ 200 MB；字段数量以实际解析结果为准。
  - 采样规模：每字段 0-20 个代表性值，总体中间数据不超过 50 MB。
- 数据留存与可追溯
  - 需将采样与判定中间结果持久化，支持后续复核；敏感值在存储与展示时需做必要脱敏处理（如掩码）。

## 5. 性能与质量要求
- 性能指标
  - 字段解析与枚举：针对 ≤ 200 MB 的单个转储，完成时间 ≤ 10 分钟。
  - 判定吞吐：在常规办公网络与本地执行环境下，字段判定速率 ≥ 200 字段/分钟（以“字段+代表性值”组合为单位）。
- 质量指标
  - 明显敏感字段识别准确率 ≥ 95%。
  - 边界/模糊字段进入“需审核”集合的覆盖率 ≥ 85%。
  - 文档完备性：字段覆盖率 = 已判定字段数/可解析字段数 ≥ 98%。
- 可用性指标
  - 单次运行成功率 ≥ 99%，出现可恢复性错误时可重试并给出清晰提示。

## 6. 异常场景与边界条件
- 输入异常：文件不存在/路径无效/体量超出预期/内容无法解析 → 给出明确错误与修复建议；不得创建空文档。
- 采样异常：字段无数据或为统一缺省值 → 允许采样为空并在文档中标注“无代表性值”。
- 判定异常：单字段判定失败/超时 → 标注“需审核”并记录原因；整体流程继续。
- 中断恢复：再次运行可复用中间数据，避免重复采样与判定。
- 资源限制：本地磁盘空间不足/权限不足 → 终止并提示，未写入的目标文档不应出现半成品。

## 7. 安全与合规要求
- 数据敏感性
  - 所有代表性值与判定理由视为敏感数据；文档与中间数据默认仅限本机访问。
- 访问控制
  - 输出目录需具备最小权限；禁止将中间数据或文档提交至公共仓库或外发渠道。
- 隐私保护
  - 对包含直接标识或可关联标识的值进行脱敏显示（如掩码、部分遮盖）。
- 审计留痕
  - 记录运行人、运行时间、输入文件摘要（如哈希）、字段总体统计与异常清单，便于复核。

## 8. 可观测性要求
- 关键业务事件
  - 扫描开始/结束、每张表处理完成、字段判定完成、异常与重试、文档落盘成功。
- 业务指标
  - 解析用时、判定用时、字段总量、各分类占比（True/需审核/False）、脱敏命中率、失败与重试次数。
- 运行报告
  - 运行结束后在文档“概览”中输出本次关键指标与摘要，便于管理者快速把握质量与风险点。

## 9. 范围与非目标
- 范围
  - 从本地转储解析字段 → 采样代表性值 → 业务判定 → 文档化输出。
- 非目标
  - 不改造数据库/接口；不提供对外 API；不构建持续运行的服务；不开展自动化脱敏或数据清洗。

## 10. 项目约束说明
- 技术栈约束（来自项目规范，影响需求实现方式但不改变业务目标）
  - 统一采用异步 I/O 模式，不支持阻塞式操作。
  - 日志需统一接入项目的标准日志能力，禁止使用临时打印方式。
  - 如涉及后台任务，需与项目的任务编排能力保持一致的语义（至少一次投递语义、可重试与持久化确认）。
  - 文档与中间数据的读写范围限定在 Kobe/ 约束内的路径规范下（本任务约定使用 Kobe/TempUtility/VisaDBOperation 子目录）。
  - 环境变量读取与密钥管理需遵循项目“集中管理、最小权限”的约束；不得在文档中泄漏敏感配置。
- 目录与路径约束（文档内一律使用正斜杠）
  - 输入：D:/AI_Projects/Visa/visa_db.sql
  - 中间与输出建议根路径：D:/AI_Projects/Kobe/TempUtility/VisaDBOperation
  - 需求文档输出路径：D:/AI_Projects/CodexFeatured/DevPlans/004_UserProfilingFieldClassification/DemandDescription.md

## 11. 交付与验收标准
- 交付物
  - Markdown 文档（本文件）：包含字段分类目录、统计概览、明细判定与理由、需审核清单、运行报告。
  - 可选：中间 JSON 文件，记录每字段的代表性值与原始判定结果，用于审计复核。
- 验收清单（可测试/可验证）
  - 文档覆盖所有可解析字段，字段覆盖率 ≥ 98%。
  - 每个字段具备明确的分类结论与 30-50 字中文理由。
  - 统计视图包含分类占比与关键运行指标；“需审核”清单完整。
  - 运行异常被记录并给出可复现的原因描述与修复建议。
  - 文档内容不包含具体技术实现细节与库/框架名称，聚焦“要做什么”。




## 12. 异步判定流程与 JSON 落库（新增）
- 流程概述
  - 触发：按“字段键名”收集 30–50 条最小脱敏样本，构造成请求负载。
  - 提交：调用 REST 接口创建任务，后台通过 Celery 执行判定。
  - 查询：客户端轮询或回调获取任务状态与结果，落库指的是存储分析结果到D:\AI_Projects\Kobe\TempUtility\VisaDBOperation\DatabaseDietPlan.md。
- 相关模块与接口
  - 提交接口：`Kobe/routers/task.py` 提供 `POST /task/start`（创建任务，返回 task_id）。
  - 查询接口：`GET /task/status/{task_id}`、`GET /task/result/{task_id}`。
  - 异步执行：`Kobe/SharedUtility/TaskQueue/tasks.py` 定义判定任务；`app.py` 提供 Celery 实例。
  - 数据持久化：`Kobe/SharedUtility/TaskQueue/repository/mongo.py` 提供 `coll_raw_payload`、`coll_task_result` 集合与索引。
- 判定负载（请求）
  - 键名：`field_key`（string，必填，PascalCase 或 snake_case 原样保留）。
  - 样本：`samples`（array[object|string]，长度 30–50，已脱敏的代表性取值或结构体）。
  - 约束：不得包含姓名、身份证号、手机号、邮箱、详细地址等可识别信息（PII）。
- 结果 JSON 模式（示例）
  ```json
  {
    "field_key": "UserHomeAddress",
    "label": "True|Boundary|False",
    "confidence": 0.92,
    "reasoning": "简要判定依据（不含原始PII）",
    "samples_used": 40,
    "sample_hash": "sha256:...",
    "created_at": "2025-10-10T12:00:00Z",
    "trace_id": "...",
    "task_id": "..."
  }
  ```
- 幂等与重试
  - 去重：同一 `field_key` + `sample_hash` 的重复请求复用历史结论（阈值可配置）。
  - 重试：遵循“至少一次投递”语义与退避策略；任务超时自动标记并可人工重试。
- 可观测性
  - 统一日志：使用 `Kobe/SharedUtility/RichLogger` 初始化与异常堆栈渲染。
  - 指标追踪：暴露任务计数、耗时分位、失败原因 TopN；兼容 Prometheus/OpenTelemetry。
- 安全与合规
  - 最小化采样：仅保留完成判定所需的最小字段与取值摘要。
  - 数据留存：结果与样本摘要分别设置 TTL；支持按 `trace_id` 全链路审计。

